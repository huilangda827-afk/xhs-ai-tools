# -*- coding: utf-8 -*-
"""
æµ‹è¯• LLM API è°ƒç”¨
ç”¨æ³•: uv run python scripts/test_llm.py <ä½ çš„API_KEY>
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def test_llm(api_key: str):
    """æµ‹è¯• LLM è°ƒç”¨"""
    print("=" * 60)
    print("ğŸ§ª LLM API æµ‹è¯•")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ httpx
    print("\n1ï¸âƒ£ æ£€æŸ¥ httpx...")
    try:
        import httpx
        print(f"   âœ… httpx ç‰ˆæœ¬: {httpx.__version__}")
    except ImportError:
        print("   âŒ httpx æœªå®‰è£…")
        return
    
    # 2. æ£€æŸ¥ç½‘ç»œè¿æ¥
    print("\n2ï¸âƒ£ æ£€æŸ¥ç½‘ç»œè¿æ¥...")
    try:
        r = httpx.get("https://api.deepseek.com", timeout=10)
        print(f"   âœ… DeepSeek API å¯è¾¾ (çŠ¶æ€ç : {r.status_code})")
    except Exception as e:
        print(f"   âŒ ç½‘ç»œé”™è¯¯: {e}")
        return
    
    # 3. æµ‹è¯• API è°ƒç”¨
    print("\n3ï¸âƒ£ æµ‹è¯• API è°ƒç”¨...")
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    
    data = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
        ],
        "temperature": 0.7,
        "max_tokens": 100,
    }
    
    try:
        with httpx.Client(timeout=30) as client:
            response = client.post(
                "https://api.deepseek.com/v1/chat/completions",
                headers=headers,
                json=data
            )
            
            print(f"   çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                print(f"   âœ… API è°ƒç”¨æˆåŠŸ!")
                print(f"   å›å¤: {content}")
            else:
                print(f"   âŒ API é”™è¯¯: {response.text}")
                
    except Exception as e:
        print(f"   âŒ è°ƒç”¨å¤±è´¥: {e}")
    
    # 4. æµ‹è¯•å®Œæ•´ç”Ÿæˆæµç¨‹
    print("\n4ï¸âƒ£ æµ‹è¯•å®Œæ•´ç”Ÿæˆæµç¨‹...")
    try:
        from src.generator.llm_client import generate_with_llm
        
        result = generate_with_llm(
            keyword="AIå·¥å…·",
            top_tags=["AIå·¥å…·", "æ•ˆç‡", "ChatGPT", "äººå·¥æ™ºèƒ½"],
            top_edges=[("AIå·¥å…·", "æ•ˆç‡"), ("ChatGPT", "äººå·¥æ™ºèƒ½")],
            provider="DeepSeek",
            api_key=api_key,
            style="æ¸…å•å‹"
        )
        
        if result:
            print("   âœ… ç”ŸæˆæˆåŠŸ!")
            print(f"   æ ‡é¢˜: {result.get('title', 'N/A')}")
            print(f"   æ­£æ–‡é•¿åº¦: {len(result.get('body', ''))}")
            print(f"   æ ‡ç­¾: {result.get('hashtags', [])}")
        else:
            print("   âŒ ç”Ÿæˆå¤±è´¥ï¼ˆè¿”å› Noneï¼‰")
            
    except Exception as e:
        print(f"   âŒ ç”Ÿæˆå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: uv run python scripts/test_llm.py <ä½ çš„API_KEY>")
        print("ä¾‹å¦‚: uv run python scripts/test_llm.py sk-xxxx")
        sys.exit(1)
    
    api_key = sys.argv[1]
    test_llm(api_key)
