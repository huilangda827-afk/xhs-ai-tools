# -*- coding: utf-8 -*-
"""
Graph Builder - Stage 3
æ ‡ç­¾å…±ç°å›¾æ„å»ºå™¨

åŠŸèƒ½ï¼š
- åŸºäºæ ‡ç­¾å…±ç°æ„å»ºæ— å‘å›¾
- èŠ‚ç‚¹ï¼šæ ‡ç­¾ï¼ˆtagï¼‰
- è¾¹ï¼šå…±ç°å…³ç³»
- æƒé‡ï¼šå…±ç°é¢‘ç‡
"""
import json
import networkx as nx
from typing import List, Dict, Tuple
from itertools import combinations
from collections import Counter


class TagCooccurrenceGraph:
    """æ ‡ç­¾å…±ç°å›¾æ„å»ºå™¨"""
    
    def __init__(self, data_path: str = "data/clean/annotations_clean.jsonl"):
        """
        Args:
            data_path: æ¸…æ´—åçš„æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.data_path = data_path
        self.graph = nx.Graph()
        self.items = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_items": 0,
            "total_tags": 0,
            "total_edges": 0,
            "avg_tags_per_item": 0.0
        }
    
    def load_data(self) -> List[Dict]:
        """åŠ è½½æ¸…æ´—åçš„æ•°æ®"""
        items = []
        
        try:
            with open(self.data_path, "r", encoding="utf-8") as f:
                for line in f:
                    items.append(json.loads(line.strip()))
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {self.data_path}")
            return []
        
        self.items = items
        self.stats["total_items"] = len(items)
        
        # ç»Ÿè®¡æ ‡ç­¾æ•°
        tag_counts = [len(item.get("tags", [])) for item in items]
        self.stats["avg_tags_per_item"] = sum(tag_counts) / len(tag_counts) if tag_counts else 0
        
        print(f"ğŸ“¥ åŠ è½½æ•°æ®: {len(items)} æ¡ç¬”è®°")
        print(f"ğŸ“Š å¹³å‡æ ‡ç­¾æ•°: {self.stats['avg_tags_per_item']:.2f}")
        
        return items
    
    def build_graph(self) -> nx.Graph:
        """
        æ„å»ºæ ‡ç­¾å…±ç°å›¾
        
        Returns:
            networkx.Graph: æ„å»ºå¥½çš„å›¾
        """
        print("=" * 60)
        print("ğŸ•¸ï¸  å¼€å§‹æ„å»ºæ ‡ç­¾å…±ç°å›¾")
        print("=" * 60)
        
        if not self.items:
            self.load_data()
        
        # ç»Ÿè®¡è¾¹æƒé‡ï¼ˆå…±ç°æ¬¡æ•°ï¼‰
        edge_weights = Counter()
        node_occurrences = Counter()
        
        for item in self.items:
            tags = item.get("tags", [])
            if not tags or len(tags) < 2:
                continue
            
            # ç»Ÿè®¡èŠ‚ç‚¹å‡ºç°æ¬¡æ•°
            for tag in tags:
                node_occurrences[tag] += 1
            
            # ç”Ÿæˆæ ‡ç­¾å¯¹ï¼ˆå…±ç°è¾¹ï¼‰
            for tag1, tag2 in combinations(sorted(tags), 2):
                edge_weights[(tag1, tag2)] += 1
        
        # æ·»åŠ èŠ‚ç‚¹
        for tag, count in node_occurrences.items():
            self.graph.add_node(tag, weight=count)
        
        # æ·»åŠ è¾¹
        for (tag1, tag2), weight in edge_weights.items():
            self.graph.add_edge(tag1, tag2, weight=weight)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_tags"] = self.graph.number_of_nodes()
        self.stats["total_edges"] = self.graph.number_of_edges()
        
        print(f"âœ… å›¾æ„å»ºå®Œæˆ")
        print(f"  èŠ‚ç‚¹æ•°ï¼ˆæ ‡ç­¾ï¼‰: {self.stats['total_tags']}")
        print(f"  è¾¹æ•°ï¼ˆå…±ç°å…³ç³»ï¼‰: {self.stats['total_edges']}")
        print("=" * 60)
        
        return self.graph
    
    def get_top_nodes(self, n: int = 10) -> List[Tuple[str, int]]:
        """
        è·å–å‡ºç°é¢‘ç‡æœ€é«˜çš„æ ‡ç­¾
        
        Args:
            n: è¿”å›æ•°é‡
            
        Returns:
            [(tag, frequency), ...]
        """
        if not self.graph.nodes:
            return []
        
        node_weights = [(node, data.get("weight", 0)) 
                        for node, data in self.graph.nodes(data=True)]
        node_weights.sort(key=lambda x: x[1], reverse=True)
        
        return node_weights[:n]
    
    def get_top_edges(self, n: int = 10) -> List[Tuple[str, str, int]]:
        """
        è·å–å…±ç°é¢‘ç‡æœ€é«˜çš„æ ‡ç­¾å¯¹
        
        Args:
            n: è¿”å›æ•°é‡
            
        Returns:
            [(tag1, tag2, weight), ...]
        """
        if not self.graph.edges:
            return []
        
        edges_with_weights = [(u, v, data.get("weight", 0)) 
                              for u, v, data in self.graph.edges(data=True)]
        edges_with_weights.sort(key=lambda x: x[2], reverse=True)
        
        return edges_with_weights[:n]
    
    def get_graph_stats(self) -> Dict:
        """è·å–å›¾çš„ç»Ÿè®¡ä¿¡æ¯"""
        if not self.graph:
            return self.stats
        
        # è®¡ç®—è¿é€šåˆ†é‡
        num_components = nx.number_connected_components(self.graph)
        
        # è®¡ç®—å¹³å‡åº¦
        degrees = [deg for node, deg in self.graph.degree()]
        avg_degree = sum(degrees) / len(degrees) if degrees else 0
        
        self.stats.update({
            "num_components": num_components,
            "avg_degree": avg_degree,
            "density": nx.density(self.graph)
        })
        
        return self.stats
    
    def save_graph(self, output_path: str = "data/output/tag_graph.gexf"):
        """
        ä¿å­˜å›¾åˆ°æ–‡ä»¶
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        import os
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        nx.write_gexf(self.graph, output_path)
        print(f"ğŸ’¾ å›¾å·²ä¿å­˜: {output_path}")


def main():
    """æµ‹è¯•å…¥å£"""
    builder = TagCooccurrenceGraph()
    graph = builder.build_graph()
    
    print("\nğŸ“Š Top 10 æ ‡ç­¾:")
    for tag, freq in builder.get_top_nodes(10):
        print(f"  {tag}: {freq}")
    
    print("\nğŸ”— Top 10 å…±ç°æ ‡ç­¾å¯¹:")
    for tag1, tag2, weight in builder.get_top_edges(10):
        print(f"  {tag1} â†” {tag2}: {weight}")
    
    print(f"\nğŸ“ˆ å›¾ç»Ÿè®¡: {builder.get_graph_stats()}")
    
    builder.save_graph()


if __name__ == "__main__":
    main()
